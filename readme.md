## Introduction

This repository contains preprocessed data and code to generate the plots in the manuscript [Rats strategically manage during learning perceptual learning](https://www.biorxiv.org/content/10.1101/2020.09.01.259911v1.abstract). 


## Data

Animal data (pickle files) stored in `_pickledata/` directory:
    
    AK_and_AL_Cohorts\...
    AK_Cohort\...
    AL_and_AM_Cohorts\...
    AL_Cohort\...
    AM_Cohort\...
    AN_Cohort\...
    csv\ # for running HDDM model fits
    optimality_parsed_results.pickle # for model fitting
	
HDDM model fits

	_hddmmodels\...


## Learning Drift Diffusion Model (LDDM)

Stored in `_lddm/` directory

**directories**

- `blobs`: contains the pixel stimuli seen by the rats and the LDDM
- `figs`: contains figures generated by scripts
- `rnn_sim_res_blob_lr_0.1_bs_50.0_dt0.0005_gam0.01_al0.05`: pixel simulation model run
- `rnn_sim_res2_blob_lr_0.1_bs_50.0_dt0.0005_gam0.01_al0.05`: pixel simulation model run
- `rnn_sim_res2_gauss_lr_0.1_dt0.0005_gam0.01_al0.05`: gaussian stimulus simulation model run

**scripts**

`launch_RNN_simulations.ipynb`: runs recurrent neural net simulations on a SLURM cluster using submitit. computationally expensive! not necessary for visualizing because finished simulations are included

`figure_RNN_reduction_comparison.ipynb`: loads the results of simulations produced by 'launch_RNN_simulations.ipynb'. This package contains the results of several runs and so it is not necessary to run launch_RNN_simulation

`figure_threshold_policies.ipynb`: plots trajectories under different threshold policies (requires `reduction.py`)


## Analysis Code for Figures

Analysis is spread out across a few iPython notebooks. Which plot is in which notebook is noted below.


Figure 1: Trained rats solve the speed-accuracy trade-off
- a – cartoon
- b – **`perf_frontiers.ipynb`**
- c,d – **`learning_experiments_and_param_analysis.ipynb`**

Figure 2: Rats do not greedily maximize instantaneous reward rate during learning
- a–f – **`learning_experiments_and_param_analysis.ipynb`**

Figure 3: Recurrent Neural Network and Learning Drift Diffusion Model
- a – cartoon
- b – cartoon
- c–f – **`_lddm/figure_RNN_reduction_comparison.ipynb`**

Figure 4: Model reveals rat learning dynamics lead to higher instantaneous reward rate and long-term rewards than greedily maximizing reward rate
- a–e – **`_lddm/figure_threshold_policies.ipynb`**
- f – LS-iRR tradeoff cartoon

Figure 5: Longer reaction times lead to faster learning and higher instantaneous reward rates
- a – cartoon
- b,d–g – **`rt_restriction_experiment.ipynb`**
- c
- h
- i
- j
- k

Figure 6: Rats choose reaction time based on stimulus learnability
- a – cartoon
- b - **`learning_experiments_and_param_analysis.ipynb`**
- c
- d – **`regular_v_new_visible_stim_experiment.ipynb`** (black curve & inset), **`regular_v_new_transparent_stim_experiment.ipynb`** (grey curve)
- e – **`regular_v_new_visible_stim_experiment.ipynb`**
- f
- g

Figure 7: Rats that slowed down reaction times the most reached a higher instantaneous reward rate sooner and collected more reward
- a – 
- b – **`regular_v_new_visible_stim_experiment.ipynb`**
- c – **`regular_v_new_visible_stim_experiment.ipynb`**

Figure 1 - figure supplement 1: Task schematic for error trials
- a – cartoon

Figure 1 - figure supplement 2: Fraction of ignored trials during learning
- a – cartoon
- b,c – **`learning_experiments_and_param_analysis.ipynb`**

Figure 1 - figure supplement 3: Drift-diffusion model data fits
- a,b – **`hddm_fit.ipynb`**

Figure 1 - figure supplement 4: Estimating T0
- a,b – **`learning_experiments_and_param_analysis.ipynb`**
- c – **`interlickinterval_hist.py`** (requires **`mw_parse_initial_170623.py`**) 
- d – cartoon of visual latency
- e – cartoon
- f – **`learning_experiments_and_param_analysis.ipynb`** (generated by modifying T0 value for OPC plots)
- g – **`learning_experiments_and_param_analysis.ipynb`** (generated by modifying T0 value for OPC plots)

Figure 1 - figure supplement 5: Analysis of voluntary intertrial intervals
- a–d – **`learning_experiments_and_param_analysis.ipynb`** 

Figure 1 - figure supplement 6: Mandatory post-error and post-correct response-to-stimulus interval times
- a – cartoon
- b – cartoon

Figure 1 - figure supplement 7: Reward rate sensitivity to T0 and voluntary intertrial interval
- a–d – **`learning_experiments_and_param_analysis.ipynb`** 

Figure 2 - figure supplement 1: Comparison of training regimes
- a – cartoon
- b–i – **`learning_experiments_and_param_analysis.ipynb`** 

Figure 3 - figure supplement 1: Analytical reduction of _lddm matches error-corrective learning neural network dynamics during learning
- a – cartoon
- b–g – **`_lddm/figure_RNN_reduction_comparison.ipynb`**

Figure 4 - figure supplement 1: Allowing both drift rate & threshold to vary with learning provides best DDM model fits
- a,b – **`hddm_fit_revisions.ipynb`**

Figure 4 - figure supplement 2: Simple DDM fits indicate threshold decreases and drift rate increases during learning
- a–f – **`hddm_fit_revisions.ipynb`**

Figure 4 - figure supplement 3: Simple DDM + fixed drift rate variability fits indicate threshold decreases and drift rate increases during learning
- a–f – **`hddm_fit_revisions.ipynb`**

Figure 4 - figure supplement 4: Simple DDM + variable drift rate variability fits indicate threshold decreases and drift rate increases during learning
- a–f – **`hddm_fit_revisions.ipynb`**

Figure 4 - figure supplement 5: Model reveals rat learning dynamics resemble optimal trajectory without relinquishing initial rewards
- a–d – **`_lddm/figure_threshold_policies.ipynb`** (requires normalizing by greedy model)

Figure 6 - figure supplement 1: Reaction time analysis of transparent stimuli experiment
- a,b – **`190609_opc_plots.ipynb`**

Figure 6 - figure supplement 2: Vincentized reaction time distributions throughout learning
- a–c – **`learning_experiments_and_param_analysis.ipynb`**

Figure 6 - figure supplement 3: Simple DDM + variable drift rate variability fits for transparent stimuli
- a – **`hddm_fit_revisions.ipynb`**

Figure 6 - figure supplement 4: Analysis of stimulus-independent strategies for transparent stimuli
- a,b – **`_psytrack/transparent_stim_rt_supplemental_psytrack.ipynb`**

Figure 6 - figure supplement 5: Post-error slowing during rat learning dynamics
- a,b – **`learning_experiments_and_param_analysis.ipynb`**
- c,d – **`regular_v_new_visible_stim_experiment.ipynb`**


## Dependencies, environments etc

Behavioral data analysis code was written in Python 2.7 with standard libraries (try the `py2.yml` environment file). PsyTrack was run in Python 3.8 (try the `py38.yml` environment file).

Loading data files and figure filenames may require editing to avoid "no such directory" errors. 